# Analysis Rationale and Interim Findings

Last updated: 2026-02-11

## Purpose

This note records:

1. Why we structured the first-pass analysis the way we did.
2. What we learned so far from party and Congress-control breakouts.
3. What remains unresolved before stronger claims.

It is a narrative companion to:

- `spec/metrics_v1.yaml`
- `spec/metrics_rationale.md`
- `reports/scoreboard.md` (generated; not committed)

## Why This Framing

Core question: how measured U.S. economic performance differs across presidential party, while checking whether congressional control is a material confounder.

Key design choices and rationale:

- Reproducible public sources only.
  - Every metric should be reproducible from online data via code.
- Multiple metric families, not one headline number.
  - Growth, labor, inflation, markets, recessions, and fiscal outcomes each capture different channels.
- Multiple transforms per family (level, term total, per-year/CAGR).
  - Reduces cherry-picking risk from choosing only one transform.
- Binary Congress control checks.
  - Use unified vs divided and chamber-alignment states to keep cells interpretable.
- Within-president diagnostic.
  - Compare unified vs divided periods within the same president-term to reduce confounding from "which president" or broad era mix.

Important interpretation guardrail:

- Congress can be both confounder and mediator. "Controlling for Congress" is a robustness check, not an automatic causal upgrade.

## What We Learned So Far

These are interim patterns from the current `reports/scoreboard.md`, especially the section:

- `## Within-President Unified vs Divided Check`

Summary:

- The added within-president check is useful (not just cosmetic). It asks: for the same president-term, do metrics differ between unified and divided periods?
- The check is now machine-readable via `reports/within_president_unified_delta_v1.csv` (generated by `rb scoreboard`).
- The check now supports a robustness filter for short windows via `rb scoreboard --within-president-min-window-days N` (default `0`).
- `rb scoreboard` now shows significance diagnostics by default (`q`, `p`, CI, `q<0.05`, `q<0.10`, tier) by reading the latest randomization outputs.
- If randomization outputs are missing/stale, scoreboard significance columns are blank/outdated; regenerate with `rb randomization` before publishing.
- For several macro metrics, unified-minus-divided deltas are directionally similar across parties.
  - Real GDP growth (QoQ annualized) shows positive U-D for both D and R in current output.
  - CPI YoY (NSA) shows negative U-D for both D and R in current output.
- Some market diagnostics are mixed by party (example: Sharpe ratio), indicating the relationship is not one-directional everywhere.
- Cell sizes are small for many metrics (`n(pres with both)` often low), so these are diagnostic signals, not final estimates.

Interpretation:

- Congress alignment appears potentially material for some outcomes.
- The current results do not justify a claim that Congress fully explains party differences.
- The current results also do not justify ruling Congress out.

## What This Check Is (and Is Not)

This check is:

- A robustness test for confounding by congressional control.
- A way to reduce composition bias across different presidents.

This check is not:

- A causal identification strategy.
- A substitute for fully specified uncertainty analysis and robustness reporting.

## Key Decisions From Project History

- Data access stack:
  - Prefer official APIs/sources (FRED API, Ken French, Congress pages) over one-off manual fetches where possible.
  - Keep credentials in `.env`; current pipeline already uses `FRED_API_KEY`.
- Presidential-party source reliability:
  - Avoid relying on Wikidata as a sole truth source for party labels; prefer congressional/official structured sources where possible.
- S&P history handling:
  - Keep modern S&P 500 (1957+) separate from pre-1957 backfilled SPX segment.
  - Do not stitch into one headline series.
- Congress-control framing:
  - Keep binary unified/divided and chamber alignment as primary control views (simplicity and cell-size stability).
- Shock-years concern:
  - Do not hard-code subjective shock exclusions into primary results.
  - If used, treat shock adjustments as explicit sensitivity analyses in a separate section.
- Validation warning interpretation:
  - Coverage warnings are expected when president windows extend earlier than a metric's data history.
  - Treat these as a scope/coverage note unless they reflect broken ingestion or boundary logic.

## Open Risks To Track

- Small-cell instability in within-president checks (`n(pres with both)` can be low).
- Boundary sensitivity for short windows and CAGR edge cases.
- Vintage/revision drift in macro series (results can move across download dates).

## Threshold Sensitivity Snapshot (Within-President U-D)

Using the new filter (`--within-president-min-window-days`), a quick `0/30/90` check shows:

- GDP growth (QoQ annualized) is fairly stable:
  - D mean U-D: `0.471` (unchanged across `0/30/90`)
  - R mean U-D: `1.149` -> `1.149` -> `1.219`
- CPI YoY (NSA) is directionally stable (negative U-D for both parties), with moderate magnitude shifts:
  - D: `-3.269` -> `-3.567` -> `-3.567`
  - R: `-0.251` -> `-0.277` -> `-0.253`
- Market Sharpe is stable for D and modestly shifts for R:
  - D: `-0.231` (unchanged)
  - R: `0.867` -> `0.867` -> `0.944`
- S&P CAGR is sensitive for D:
  - D: `1.197` -> `-9.176` -> `-9.176` (and `n_with_both` drops from `4` to `3`)
  - R: `7.017` -> `6.221` -> `6.876` (still low `n_with_both=2`)

Takeaway:

- Macro flow metrics look more robust to short-window filtering than some level-return metrics.
- For market-level CAGR, short-window handling can materially change inferred sign/magnitude, so this should be explicitly labeled as sensitivity-dependent.

## Permutation Robustness Snapshot

New command:

- `rb randomization`

Current outputs:

- `reports/permutation_party_term_v1.csv` (primary metrics)
- `reports/permutation_unified_within_term_v1.csv` (primary metrics)
- `reports/permutation_party_term_all_v1.csv` (all metrics)
- `reports/permutation_unified_within_term_all_v1.csv` (all metrics)
- `reports/permutation_evidence_summary_v1.csv` (compact evidence-tier summary by analysis and metric family)
- `reports/permutation_evidence_summary_v1.md` (human-readable confirmatory/supportive summary)
- `reports/permutation_evidence_compare_v1.csv` (baseline vs stricter-profile tier comparison)

What it does:

- Term-level test: permutes D/R labels across eligible term observations (optionally within year-blocks) and reports two-sided permutation p-values for observed D-R mean differences.
- Within-president control test: permutes unified/divided assignment within each president-term's regime windows and reports two-sided permutation p-values for mean within-term delta (U-D).
- Both outputs now include Benjamini-Hochberg FDR-adjusted `q_bh_fdr` columns in addition to raw `p_two_sided`.
- Both outputs now include bootstrap 95% confidence intervals (`bootstrap_ci95_low`, `bootstrap_ci95_high`) for the observed estimand.
- Both outputs now include a rule-based evidence classification:
  - `confirmatory` / `supportive` / `exploratory`
  - with audit columns (`passes_q_threshold`, `passes_q_lt_005`, `passes_q_lt_010`, `passes_ci_excludes_zero`, `passes_min_n`, thresholds used).

Early read (all-metrics run):

- Several labor/macro term-level differences have relatively small permutation p-values (for example unemployment change and payroll jobs-per-year).
- Within-president unified/divided results are generally weaker and sample-limited; the smallest p-values often occur in metrics with small `n_presidents_with_both`.
- After BH adjustment (`q_bh_fdr`):
  - All-metrics term-level run: `7` metrics are below `q < 0.10`, of which `2` are below `q < 0.05`.
  - Within-president unified/divided run remains weak after adjustment (no low-q signals; mostly high-q, small-`n` cells).

Interpretation caveats:

- These permutation p-values are exploratory; use `q_bh_fdr` for multiple-testing-aware screening.
- Small-cell metrics can look extreme by chance; treat low-p small-`n` findings as hypotheses to stress-test, not conclusions.
- For screening, prefer `q_bh_fdr` over raw p-values when comparing many metrics at once.

## Significance Tension and How To Resolve It

Current tension (all-metrics snapshots):

- Term-level party test (`reports/permutation_party_term_all_v1.csv`):
  - `p < 0.05`: 8 metrics
  - `q_bh_fdr < 0.10`: 7 metrics
  - `q_bh_fdr < 0.05`: 2 metrics
  - bootstrap CI excludes zero: 11 metrics
- Within-president unified/divided test (`reports/permutation_unified_within_term_all_v1.csv`):
  - `p < 0.05`: 1 row
  - `q_bh_fdr < 0.10`: 0 rows
  - bootstrap CI excludes zero: 12 rows (mostly small-`n` cells)

Why they disagree:

- Raw p-values do not account for multiplicity across many metrics/transforms.
- BH-adjusted q-values are stricter and can wash out borderline effects.
- Bootstrap CIs answer precision around effect size, not multiplicity; with small samples they can be unstable and still exclude zero.
- Many transforms are correlated variants of the same underlying signal, which complicates naive “count of significant metrics” interpretation.

Current resolution policy (for reporting):

1. **Primary claim threshold** (confirmatory tone):
   - Require both:
     - `q_bh_fdr < 0.05` (default confirmatory threshold)
     - minimum sample threshold met (`n_obs >= 12` for term-level; `n_presidents_with_both >= 5` for within-president rows)
2. **Supportive evidence** (suggestive tone):
   - Require both:
     - `q_bh_fdr < 0.10`
     - minimum sample threshold met
   - and not already confirmatory under the stricter threshold.
3. **Exploratory only**:
   - Anything else.
4. **No metric-family cherry-picking**:
   - Report results by family + transform grid, not single best metric.
   - For headline statements, prioritize pre-declared primary metrics.
5. **Always report continuous stats**:
   - Include `q_bh_fdr`, `p_two_sided`, and CI bounds directly in tables.
   - Treat tiers as convenience labels, not the primary evidence object.
   - CI exclusion is reported as an uncertainty diagnostic, not a hard tier gate.

Can CI bands be collapsed to one equivalent p/q number?

- Not exactly in this pipeline.
- Here, `q_bh_fdr` comes from permutation p-values with BH adjustment, while CI comes from bootstrap percentiles. Those are different inferential procedures and are not algebraic inverses of each other.
- CI and p are directly convertible only when derived from the same underlying test model.
- So we keep one multiplicity-aware continuous number (`q_bh_fdr`) plus CI for effect-size uncertainty.

Implication for current read:

- Term-level evidence is stronger than within-president unified/divided evidence.
- Within-president rows are currently mostly exploratory due to small `n_presidents_with_both` and lack of low q-values.
- We should avoid claiming “Congress effect is significant” globally at this stage; treat it as mixed/diagnostic.

Operational status:

- This policy is now encoded in `rb randomization` outputs.
- A compact family-level summary table is now generated automatically.
- A narrative markdown summary is now generated automatically.
- A comparison table is now generated via `rb randomization-compare` to track baseline-vs-stricter tier shifts metric-by-metric.
- The main scoreboard now includes significance columns by default, sourced from randomization outputs.
- `rb randomization` defaults were hardened on 2026-02-11:
  - `--term-block-years` now defaults to `20`.
  - `--permutations` now defaults to `10000`.
- `rb randomization` now excludes selected diagnostic-only metrics from the inferential battery by default:
  - `sp500_backfilled_pre1957_term_pct_change`
  - `sp500_backfilled_pre1957_term_cagr_pct`
  - `ff_mkt_excess_return_ann_arith`
  - Use `--include-diagnostic-metrics` to opt these back in.
- A multi-seed stability report is now available via:
  - `rb randomization-stability --seeds 42,137,271`
  - Output: `reports/permutation_seed_stability_v1.csv`
- A dual-inference primary table is now available via:
  - `rb inference-table --nw-lags 1`
  - Outputs:
    - `reports/inference_table_primary_v1.csv`
    - `reports/inference_table_primary_v1.md`
  - Table includes side-by-side permutation (`p`, `q`, tier) and HAC/Newey-West diagnostics (SE, z, p), plus disagreement flags.
- Historical all-metrics tier counts (pre-hardening defaults; retained for comparison context):
  - Term-level party differences: `confirmatory=2`, `supportive=5`, `exploratory=30`.
  - Within-president unified/divided: `confirmatory=0`, `supportive=0`, `exploratory=74`.
- Sensitivity check (stricter settings: `term_block_years=20`, `within-president-min-window-days=90`):
  - Term-level party differences shift to `confirmatory=0`, `supportive=0`, `exploratory=37`.
  - Within-president unified/divided remains weak (`confirmatory=0`, `supportive=0`, `exploratory=74`).

Interpretation of this sensitivity:

- Some baseline “confirmatory” term-level findings are sensitive to stronger temporal-block assumptions.
- Publication claims should therefore distinguish:
  - baseline-confirmatory (under default randomization settings), versus
  - robustness-confirmatory (still confirmatory/supportive under stricter settings).
- At the moment, evidence is stronger for “supportive macro/labor pattern” than for hard confirmatory claims robust to stricter blocking.
- In the current baseline-vs-stricter comparison (`reports/permutation_evidence_compare_v1.csv`):
  - term-level rows: `30 same`, `7 weaker`, `0 stronger`
  - within-president rows: `74 same`, `0 stronger`, `0 weaker`

## Literature Cross-Check: Is This Significance Practice Standard?

Yes, for this niche (party-regime macro/finance comparisons), our current approach is aligned with better prior work, with one key caveat.

What the stronger local literature does:

- `literature/blinder-watson-2014-presidents-us-economy/notes.md`
  - Uses term-aware uncertainty (clustered-by-term and Newey-West/HAC).
  - Uses a random party-label reassignment (permutation-style) p-value as a small-sample check.
- `literature/aea-why-economy-better-under-democrats/notes.md`
  - Explains the same random-label logic as a core response to the small-`n` objection.
- `literature/santa-clara-valkanov-presidential-puzzle/notes.md`
  - Uses Newey-West plus randomization-bootstrap and quantile-robust checks to guard against outliers and small-sample fragility.
- `literature/factcheck-2015-economy-better-democrats/notes.md`
  - Mirrors the same interpretation pattern: some gaps are statistically persuasive, others are not, especially in volatile market series.

What this implies for us:

- Using permutation p-values + BH-adjusted q-values + bootstrap CI bands is methodologically defensible as an inferential robustness stack.
- This is standard as **associational evidence** in this literature, not a causal identification strategy.
- We should avoid pure coin-flip rhetoric without explicit assumptions, as highlighted by `literature/belfer-frankel-2024-historical-puzzle/notes.md`.

Bottom line:

- Our significance framework is directionally consistent with the best papers in `./literature`.
- The right communication standard is: "robust association under declared assumptions," not "policy causation proven by significance."

## Strengths and Weaknesses vs Best Literature

Relative to the strongest references in `./literature` (especially Blinder-Watson and Santa-Clara/Valkanov):

Current strengths:

- Reproducibility discipline is stronger than most published writeups.
  - Full CLI pipeline, explicit specs, and machine-readable outputs (`scoreboard`, randomization tables, claims table).
- Multiplicity-aware reporting is stronger than most legacy papers.
  - We report `q_bh_fdr`, not only raw p-values, and keep CI bands visible.
- Sensitivity transparency is stronger.
  - We already compare baseline vs stricter profiles and record tier downgrades/upgrades.
- Congress-control diagnostics are broader.
  - We include both cross-regime and within-president unified/divided checks, instead of president-only comparisons.

Current weaknesses / gaps:

- Classical econometric inference layer is thinner than the best literature.
  - We currently lean on permutation/bootstrap; we do not yet report a parallel HAC / few-cluster-robust table for the same estimands.
- Explanatory decomposition is less developed.
  - Blinder-Watson-style decomposition of the growth gap into candidate channels (oil, productivity, global growth, etc.) is not yet implemented.
- Small-cell/power diagnostics are not explicit enough.
  - We flag low `n`, but do not yet report minimum detectable effects or power proxies for each estimand.
- Endpoint/vintage uncertainty is still under-documented.
  - We note data revision risk, but we do not yet version full vintages or publish a revision sensitivity panel.
- Congress-control interpretation remains diagnostic.
  - Within-president results are mostly exploratory at current sample sizes; this is useful but not decisive.

## Potential Next Steps (Methodology)

1. Add a dual-inference output for each primary estimand:
   - permutation/q + HAC/Newey-West + few-cluster-robust side-by-side in one table.
2. Pre-register a primary metric set and transform hierarchy in the spec:
   - one primary metric per family, with secondaries explicitly labeled.
3. Add power/precision diagnostics:
   - report `n`, effective clusters, bootstrap SE, and a rough minimum-detectable-effect column.
4. Implement a decomposition module for growth and labor gaps:
   - start with oil shock proxies, global growth, productivity, and initial-condition controls.
5. Add a historical-vintage sensitivity panel:
   - recompute headline claims using at least two download dates (or vintages where available).
6. Extend Congress checks with strict binary dominance framing:
   - president+both-houses vs all other regimes, with explicit cell-size and uncertainty caveats.
7. Add a publication-mode claims gate:
   - only allow "confirmatory" labels when both inference stacks agree on direction and significance tier.

## Immediate Next Steps

1. Define which metrics are headline primary claims versus secondary diagnostics before re-running final tables.
2. Add permutation stability checks across multiple seeds and larger `permutations` to quantify Monte Carlo noise in borderline rows.
3. Add a short publication-ready narrative template that maps directly from the claims table rows (no manual cherry-picking).

## Claims Table

A machine-readable baseline-vs-strict claims table is now produced via:

```sh
rb claims-table \
  --baseline-party-term reports/permutation_party_term_all_v1.csv \
  --strict-party-term reports/permutation_party_term_block20_all_v1.csv \
  --baseline-within reports/permutation_unified_within_term_all_v1.csv \
  --strict-within reports/permutation_unified_within_term_min90_all_v1.csv \
  --output reports/claims_table_v1.csv
```

Default invocation uses the same paths:

```sh
rb claims-table
```

## Reproduce Current Outputs

```sh
uv sync
rb ingest --refresh
rb presidents --source congress_legislators --granularity tenure --refresh
rb compute
rb congress --refresh
rb regimes --refresh
rb randomization --all-metrics
rb scoreboard --all-metrics
rb validate
```

## Baseline vs Stricter Profile Commands

Baseline (current defaults used in most summaries):

```sh
rb randomization --all-metrics \
  --output-party-term reports/permutation_party_term_all_v1.csv \
  --output-unified-within-term reports/permutation_unified_within_term_all_v1.csv \
  --output-evidence-summary reports/permutation_evidence_summary_v1.csv \
  --output-evidence-md reports/permutation_evidence_summary_v1.md
```

Stricter sensitivity profile:

```sh
rb randomization --all-metrics \
  --term-block-years 20 \
  --within-president-min-window-days 90 \
  --output-party-term reports/permutation_party_term_block20_all_v1.csv \
  --output-unified-within-term reports/permutation_unified_within_term_min90_all_v1.csv \
  --output-evidence-summary reports/permutation_evidence_summary_block20_min90_v1.csv \
  --output-evidence-md reports/permutation_evidence_summary_block20_min90_v1.md
```

Compare profiles:

```sh
rb randomization-compare \
  --base-party-term reports/permutation_party_term_all_v1.csv \
  --alt-party-term reports/permutation_party_term_block20_all_v1.csv \
  --base-within reports/permutation_unified_within_term_all_v1.csv \
  --alt-within reports/permutation_unified_within_term_min90_all_v1.csv \
  --output reports/permutation_evidence_compare_v1.csv
```

Build claims table:

```sh
rb claims-table \
  --baseline-party-term reports/permutation_party_term_all_v1.csv \
  --strict-party-term reports/permutation_party_term_block20_all_v1.csv \
  --baseline-within reports/permutation_unified_within_term_all_v1.csv \
  --strict-within reports/permutation_unified_within_term_min90_all_v1.csv \
  --output reports/claims_table_v1.csv
```
