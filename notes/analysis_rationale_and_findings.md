# Analysis Rationale and Interim Findings

Last updated: 2026-02-11

## Purpose

This note records:

1. Why we structured the first-pass analysis the way we did.
2. What we learned so far from party and Congress-control breakouts.
3. What remains unresolved before stronger claims.

It is a narrative companion to:

- `spec/metrics_v1.yaml`
- `spec/metrics_rationale.md`
- `reports/scoreboard.md` (generated; not committed)

## Why This Framing

Core question: how measured U.S. economic performance differs across presidential party, while checking whether congressional control is a material confounder.

Key design choices and rationale:

- Reproducible public sources only.
  - Every metric should be reproducible from online data via code.
- Multiple metric families, not one headline number.
  - Growth, labor, inflation, markets, recessions, and fiscal outcomes each capture different channels.
- Multiple transforms per family (level, term total, per-year/CAGR).
  - Reduces cherry-picking risk from choosing only one transform.
- Binary Congress control checks.
  - Use unified vs divided and chamber-alignment states to keep cells interpretable.
- Within-president diagnostic.
  - Compare unified vs divided periods within the same president-term to reduce confounding from "which president" or broad era mix.

Important interpretation guardrail:

- Congress can be both confounder and mediator. "Controlling for Congress" is a robustness check, not an automatic causal upgrade.

## What We Learned So Far

These are interim patterns from the current `reports/scoreboard.md`, especially the section:

- `## Within-President Unified vs Divided Check`

Summary:

- The added within-president check is useful (not just cosmetic). It asks: for the same president-term, do metrics differ between unified and divided periods?
- The check is now machine-readable via `reports/within_president_unified_delta_v1.csv` (generated by `rb scoreboard`).
- The check now supports a robustness filter for short windows via `rb scoreboard --within-president-min-window-days N` (default `0`).
- `rb scoreboard` now shows significance diagnostics by default (`q`, `p`, CI, `q<0.05`, `q<0.10`, tier) by reading the latest randomization outputs.
- If randomization outputs are missing/stale, scoreboard significance columns are blank/outdated; regenerate with `rb randomization` before publishing.
- For several macro metrics, unified-minus-divided deltas are directionally similar across parties.
  - Real GDP growth (QoQ annualized) shows positive U-D for both D and R in current output.
  - CPI YoY (NSA) shows negative U-D for both D and R in current output.
- Some market diagnostics are mixed by party (example: Sharpe ratio), indicating the relationship is not one-directional everywhere.
- Cell sizes are small for many metrics (`n(pres with both)` often low), so these are diagnostic signals, not final estimates.

Interpretation:

- Congress alignment appears potentially material for some outcomes.
- The current results do not justify a claim that Congress fully explains party differences.
- The current results also do not justify ruling Congress out.

## What This Check Is (and Is Not)

This check is:

- A robustness test for confounding by congressional control.
- A way to reduce composition bias across different presidents.

This check is not:

- A causal identification strategy.
- A substitute for fully specified uncertainty analysis and robustness reporting.

## Key Decisions From Project History

- Data access stack:
  - Prefer official APIs/sources (FRED API, Ken French, Congress pages) over one-off manual fetches where possible.
  - Keep credentials in `.env`; current pipeline already uses `FRED_API_KEY`.
- Presidential-party source reliability:
  - Avoid relying on Wikidata as a sole truth source for party labels; prefer congressional/official structured sources where possible.
- S&P history handling:
  - Keep modern S&P 500 (1957+) separate from pre-1957 backfilled SPX segment.
  - Do not stitch into one headline series.
- Congress-control framing:
  - Keep binary unified/divided and chamber alignment as primary control views (simplicity and cell-size stability).
- Shock-years concern:
  - Do not hard-code subjective shock exclusions into primary results.
  - If used, treat shock adjustments as explicit sensitivity analyses in a separate section.
- Validation warning interpretation:
  - Coverage warnings are expected when president windows extend earlier than a metric's data history.
  - Treat these as a scope/coverage note unless they reflect broken ingestion or boundary logic.

## Open Risks To Track

- Small-cell instability in within-president checks (`n(pres with both)` can be low).
- Boundary sensitivity for short windows and CAGR edge cases.
- Vintage/revision drift in macro series (results can move across download dates).

## Metric-Set Expansion Update (2026-02-11)

To reduce omission risk and make transform coverage more symmetric, we expanded the spec with:

- Labor-force utilization:
  - `CIVPART` (`labor_force_participation` family)
- Core inflation:
  - `CPILFESL` (core CPI)
  - `PCEPILFE` (core PCE)
- Monetary/term-structure context:
  - `FEDFUNDS` (effective fed funds rate)
  - `DGS10` (10-year Treasury yield)
  - `T10Y2Y` (10y-2y spread)
  - plus explicit inversion diagnostics from `T10Y2Y < 0`:
    - inversion share of trading days
    - inversion start count
    - monthly-EOP inversion share/start variants (FRED resample) for horizon robustness

Transform policy applied:

- For rate/spread series (`CIVPART`, `FEDFUNDS`, `DGS10`, `T10Y2Y`): mean, end, pp change, pp change per year.
- For core price-level series (`CPILFESL`, `PCEPILFE`): YoY mean, MoM annualized log-diff mean, term pct change, term CAGR.

Early empirical read after rebuild:

- New primary metrics (`labor_force_participation_rate_mean`, `fedfunds_policy_rate_mean`) are currently exploratory in permutation output (`q_bh_fdr` well above 0.10 in the latest run).
- Coverage is mechanically limited by data starts:
  - `FEDFUNDS` and core inflation start postwar (fewer eligible terms than GDP/CPI headline series).
  - `T10Y2Y` has especially short history (post-1970s), so this is currently a contextual diagnostic, not a high-power inferential signal.

Interpretation:

- The expansion adds useful macro-policy context and reduces "you omitted X" critiques.
- It does not, by itself, resolve the core inferential uncertainty; sample-size and blocking sensitivity still dominate significance stability.
- We added a lightweight spec-symmetry validator to `rb validate` so transform-pair regressions (for example per-year without total, or CAGR without term pct change) are caught automatically.

Daily vs monthly inversion robustness snapshot (latest run):

- `yield_curve_t10y2y_inversion_share`:
  - `n_obs=10`, diff(D-R)=`21.82` pp, `q=0.338`, exploratory
- `yield_curve_t10y2y_inversion_share_monthly_eop`:
  - `n_obs=10`, diff(D-R)=`22.83` pp, `q=0.336`, exploratory
- `yield_curve_t10y2y_inversion_start_count`:
  - `n_obs=37`, diff(D-R)=`-0.75`, `q=0.878`, exploratory
- `yield_curve_t10y2y_inversion_start_count_monthly_eop`:
  - `n_obs=37`, diff(D-R)=`-0.11`, `q=1.000`, exploratory
- `yield_curve_t10y2y_inversion_share_monthly_avg`:
  - `n_obs=10`, diff(D-R)=`22.05` pp, `q=0.355`, exploratory
- `yield_curve_t10y2y_inversion_start_count_monthly_avg`:
  - `n_obs=37`, diff(D-R)=`-0.06`, `q=1.000`, exploratory

Read:

- Inversion-share signal is directionally stable under daily, monthly-EOP, and monthly-AVG definitions, but remains non-confirmatory.
- Inversion-start counts are weak under all definitions; monthly resampling attenuates differences further.
- We now maintain a dedicated generated artifact for this check via:
  - `rb inversion-robustness`
  - and automatically during `rb randomization --all-metrics` (unless `--skip-inversion-robustness`)
  - outputs: `reports/inversion_definition_robustness_v1.csv` and `.md`
- We wired spec/presidents validation into CI via `.github/workflows/validate.yml` so transform-symmetry drift is caught on PRs.
- CI now also runs a minimal end-to-end smoke pipeline (`ingest -> compute -> validate`) against `spec/metrics_ci_smoke.yaml`.
- CI now includes a second smoke profile with a daily market series and non-FRED source (`spec/metrics_ci_smoke_nonfred.yaml`) to catch source-integration regressions earlier.
- CI smoke steps now wrap network-dependent ingest calls with retry/backoff to reduce transient external-failure noise.
- CI smoke ingest now avoids forced `--refresh`, so cached downloads from earlier steps in the same run can be reused.
- CI now caches smoke `data/raw` and `data/derived` artifacts across workflow runs via `actions/cache`, keyed by smoke-spec hashes.
- CI checks are now split into separate jobs (`validate-spec`, `smoke-fred`, `smoke-nonfred`) for clearer failure localization.
- We added SA CPI term-level percent/CAGR alternates (`cpi_price_level_term_pct_change_sa`, `cpi_price_level_term_cagr_pct_sa`) so NSA-vs-SA CPI level sensitivity is explicit and auditable.
- Latest SA-vs-NSA CPI level snapshot (all-metrics randomization):
  - NSA level metrics (`*_nsa`) show larger D-R differences than SA level metrics (`*_sa`) in the current run.
  - SA level metrics are currently lower-coverage (`n_obs=15` vs `21` for NSA), so this is treated as a sensitivity read, not a headline conclusion.
  - We now maintain dedicated generated artifacts:
    - `rb cpi-robustness`
    - and automatically during `rb randomization --all-metrics` (unless `--skip-cpi-robustness`)
    - outputs: `reports/cpi_sa_nsa_robustness_v1.csv` and `.md`
  - The robustness artifact now includes the CPI YoY SA-vs-NSA pair in addition to level-term pct/CAGR pairs.
  - Latest YoY snapshot in the same artifact:
    - `cpi_inflation_yoy_mean_nsa`: diff(D-R)=`2.80`, `q=0.214`, exploratory
    - `cpi_inflation_yoy_mean` (SA): diff(D-R)=`-0.19`, `q=1.000`, exploratory

## Threshold Sensitivity Snapshot (Within-President U-D)

Using the new filter (`--within-president-min-window-days`), a quick `0/30/90` check shows:

- GDP growth (QoQ annualized) is fairly stable:
  - D mean U-D: `0.471` (unchanged across `0/30/90`)
  - R mean U-D: `1.149` -> `1.149` -> `1.219`
- CPI YoY (NSA) is directionally stable (negative U-D for both parties), with moderate magnitude shifts:
  - D: `-3.269` -> `-3.567` -> `-3.567`
  - R: `-0.251` -> `-0.277` -> `-0.253`
- Market Sharpe is stable for D and modestly shifts for R:
  - D: `-0.231` (unchanged)
  - R: `0.867` -> `0.867` -> `0.944`
- S&P CAGR is sensitive for D:
  - D: `1.197` -> `-9.176` -> `-9.176` (and `n_with_both` drops from `4` to `3`)
  - R: `7.017` -> `6.221` -> `6.876` (still low `n_with_both=2`)

Takeaway:

- Macro flow metrics look more robust to short-window filtering than some level-return metrics.
- For market-level CAGR, short-window handling can materially change inferred sign/magnitude, so this should be explicitly labeled as sensitivity-dependent.

## Permutation Robustness Snapshot

New command:

- `rb randomization`

Current outputs:

- `reports/permutation_party_term_v1.csv` (primary metrics)
- `reports/permutation_unified_within_term_v1.csv` (primary metrics)
- `reports/permutation_party_term_all_v1.csv` (all metrics)
- `reports/permutation_unified_within_term_all_v1.csv` (all metrics)
- `reports/permutation_evidence_summary_v1.csv` (compact evidence-tier summary by analysis and metric family)
- `reports/permutation_evidence_summary_v1.md` (human-readable confirmatory/supportive summary)
- `reports/permutation_evidence_compare_v1.csv` (baseline vs stricter-profile tier comparison)

What it does:

- Term-level test: permutes D/R labels across eligible term observations (optionally within year-blocks) and reports two-sided permutation p-values for observed D-R mean differences.
- Within-president control test: permutes unified/divided assignment within each president-term's regime windows and reports two-sided permutation p-values for mean within-term delta (U-D).
- Both outputs now include Benjamini-Hochberg FDR-adjusted `q_bh_fdr` columns in addition to raw `p_two_sided`.
- Both outputs now include bootstrap 95% confidence intervals (`bootstrap_ci95_low`, `bootstrap_ci95_high`) for the observed estimand.
- Both outputs now include a rule-based evidence classification:
  - `confirmatory` / `supportive` / `exploratory`
  - with audit columns (`passes_q_threshold`, `passes_q_lt_005`, `passes_q_lt_010`, `passes_ci_excludes_zero`, `passes_min_n`, thresholds used).

Early read (all-metrics run):

- Several labor/macro term-level differences have relatively small permutation p-values (for example unemployment change and payroll jobs-per-year).
- Within-president unified/divided results are generally weaker and sample-limited; the smallest p-values often occur in metrics with small `n_presidents_with_both`.
- After BH adjustment (`q_bh_fdr`):
  - All-metrics term-level run: `7` metrics are below `q < 0.10`, of which `2` are below `q < 0.05`.
  - Within-president unified/divided run remains weak after adjustment (no low-q signals; mostly high-q, small-`n` cells).

Interpretation caveats:

- These permutation p-values are exploratory; use `q_bh_fdr` for multiple-testing-aware screening.
- Small-cell metrics can look extreme by chance; treat low-p small-`n` findings as hypotheses to stress-test, not conclusions.
- For screening, prefer `q_bh_fdr` over raw p-values when comparing many metrics at once.

## Significance Tension and How To Resolve It

Current tension (all-metrics snapshots):

- Term-level party test (`reports/permutation_party_term_all_v1.csv`):
  - `p < 0.05`: 8 metrics
  - `q_bh_fdr < 0.10`: 7 metrics
  - `q_bh_fdr < 0.05`: 2 metrics
  - bootstrap CI excludes zero: 11 metrics
- Within-president unified/divided test (`reports/permutation_unified_within_term_all_v1.csv`):
  - `p < 0.05`: 1 row
  - `q_bh_fdr < 0.10`: 0 rows
  - bootstrap CI excludes zero: 12 rows (mostly small-`n` cells)

Why they disagree:

- Raw p-values do not account for multiplicity across many metrics/transforms.
- BH-adjusted q-values are stricter and can wash out borderline effects.
- Bootstrap CIs answer precision around effect size, not multiplicity; with small samples they can be unstable and still exclude zero.
- Many transforms are correlated variants of the same underlying signal, which complicates naive “count of significant metrics” interpretation.

Current resolution policy (for reporting):

1. **Primary claim threshold** (confirmatory tone):
   - Require both:
     - `q_bh_fdr < 0.05` (default confirmatory threshold)
     - minimum sample threshold met (`n_obs >= 12` for term-level; `n_presidents_with_both >= 5` for within-president rows)
2. **Supportive evidence** (suggestive tone):
   - Require both:
     - `q_bh_fdr < 0.10`
     - minimum sample threshold met
   - and not already confirmatory under the stricter threshold.
3. **Exploratory only**:
   - Anything else.
4. **No metric-family cherry-picking**:
   - Report results by family + transform grid, not single best metric.
   - For headline statements, prioritize pre-declared primary metrics.
5. **Always report continuous stats**:
   - Include `q_bh_fdr`, `p_two_sided`, and CI bounds directly in tables.
   - Treat tiers as convenience labels, not the primary evidence object.
   - CI exclusion is reported as an uncertainty diagnostic, not a hard tier gate.

Can CI bands be collapsed to one equivalent p/q number?

- Not exactly in this pipeline.
- Here, `q_bh_fdr` comes from permutation p-values with BH adjustment, while CI comes from bootstrap percentiles. Those are different inferential procedures and are not algebraic inverses of each other.
- CI and p are directly convertible only when derived from the same underlying test model.
- So we keep one multiplicity-aware continuous number (`q_bh_fdr`) plus CI for effect-size uncertainty.

Implication for current read:

- Term-level evidence is stronger than within-president unified/divided evidence.
- Within-president rows are currently mostly exploratory due to small `n_presidents_with_both` and lack of low q-values.
- We should avoid claiming “Congress effect is significant” globally at this stage; treat it as mixed/diagnostic.

Operational status:

- This policy is now encoded in `rb randomization` outputs.
- A compact family-level summary table is now generated automatically.
- A narrative markdown summary is now generated automatically.
- A comparison table is now generated via `rb randomization-compare` to track baseline-vs-stricter tier shifts metric-by-metric.
- The main scoreboard now includes significance columns by default, sourced from randomization outputs.
- `rb randomization` defaults were hardened on 2026-02-11:
  - `--term-block-years` now defaults to `20`.
  - `--permutations` now defaults to `10000`.
- `rb randomization` now excludes selected diagnostic-only metrics from the inferential battery by default:
  - `sp500_backfilled_pre1957_term_pct_change`
  - `sp500_backfilled_pre1957_term_cagr_pct`
  - `ff_mkt_excess_return_ann_arith`
  - Use `--include-diagnostic-metrics` to opt these back in.
- A multi-seed stability report is now available via:
  - `rb randomization-stability --seeds 42,137,271`
  - Output: `reports/permutation_seed_stability_v1.csv`
- A dual-inference primary table is now available via:
  - `rb inference-table --nw-lags 1`
  - Outputs:
    - `reports/inference_table_primary_v1.csv`
    - `reports/inference_table_primary_v1.md`
  - Table includes side-by-side permutation (`p`, `q`, tier), HAC/Newey-West diagnostics, and president-cluster sandwich diagnostics.
  - Table now also includes rough power diagnostics for primary term-level metrics:
    - effective cluster counts
    - rough MDE proxy (`rough_mde_abs_alpha005_power080`)
    - `|effect|/MDE` scale ratio
- `rb claims-table` now supports publication-mode gating for term-level claims:
  - `--publication-mode --inference-table reports/inference_table_primary_v1.csv`
  - Confirmatory labels are downgraded when HAC significance/direction checks do not agree.
  - New output columns include:
    - `tier_baseline_publication`
    - `tier_strict_publication`
    - `publication_gate_reason_*`
- A publication-ready narrative scaffold is now available via:
  - `rb narrative-template`
  - default output: `reports/publication_narrative_template_v1.md`
  - This template is generated directly from claims/inference tables to reduce narrative cherry-picking.
- A one-command publication artifact build is now available:
  - `rb publication-bundle`
  - This runs inference table -> publication-gated claims table -> narrative template -> scoreboard with claims-aware tier columns.
  - Supports `--profile strict_vs_baseline` (default) and `--profile baseline_only`.
  - Emits a JSON run manifest by default (`reports/publication_bundle_manifest_v1.json`) with input/output paths, hashes, and thresholds.
- `rb scoreboard` can now display strict/publication tier context from claims tables:
  - default claims path: `reports/claims_table_v1.csv`
  - disable via `--no-publication-tier-columns`
  - strict/publication tier columns are wired for both party and within-president sections.
  - publication-tier cells are populated when claims were generated with `rb claims-table --publication-mode`.
- Historical all-metrics tier counts (pre-hardening defaults; retained for comparison context):
  - Term-level party differences: `confirmatory=2`, `supportive=5`, `exploratory=30`.
  - Within-president unified/divided: `confirmatory=0`, `supportive=0`, `exploratory=74`.
- Sensitivity check (stricter settings: `term_block_years=20`, `within-president-min-window-days=90`):
  - Term-level party differences shift to `confirmatory=0`, `supportive=0`, `exploratory=37`.
  - Within-president unified/divided remains weak (`confirmatory=0`, `supportive=0`, `exploratory=74`).

Interpretation of this sensitivity:

- Some baseline “confirmatory” term-level findings are sensitive to stronger temporal-block assumptions.
- Publication claims should therefore distinguish:
  - baseline-confirmatory (under default randomization settings), versus
  - robustness-confirmatory (still confirmatory/supportive under stricter settings).
- At the moment, evidence is stronger for “supportive macro/labor pattern” than for hard confirmatory claims robust to stricter blocking.
- In the current baseline-vs-stricter comparison (`reports/permutation_evidence_compare_v1.csv`):
  - term-level rows: `30 same`, `7 weaker`, `0 stronger`
  - within-president rows: `74 same`, `0 stronger`, `0 weaker`

## Literature Cross-Check: Is This Significance Practice Standard?

Yes, for this niche (party-regime macro/finance comparisons), our current approach is aligned with better prior work, with one key caveat.

What the stronger local literature does:

- `literature/blinder-watson-2014-presidents-us-economy/notes.md`
  - Uses term-aware uncertainty (clustered-by-term and Newey-West/HAC).
  - Uses a random party-label reassignment (permutation-style) p-value as a small-sample check.
- `literature/aea-why-economy-better-under-democrats/notes.md`
  - Explains the same random-label logic as a core response to the small-`n` objection.
- `literature/santa-clara-valkanov-presidential-puzzle/notes.md`
  - Uses Newey-West plus randomization-bootstrap and quantile-robust checks to guard against outliers and small-sample fragility.
- `literature/factcheck-2015-economy-better-democrats/notes.md`
  - Mirrors the same interpretation pattern: some gaps are statistically persuasive, others are not, especially in volatile market series.

What this implies for us:

- Using permutation p-values + BH-adjusted q-values + bootstrap CI bands is methodologically defensible as an inferential robustness stack.
- This is standard as **associational evidence** in this literature, not a causal identification strategy.
- We should avoid pure coin-flip rhetoric without explicit assumptions, as highlighted by `literature/belfer-frankel-2024-historical-puzzle/notes.md`.

Bottom line:

- Our significance framework is directionally consistent with the best papers in `./literature`.
- The right communication standard is: "robust association under declared assumptions," not "policy causation proven by significance."

## Strengths and Weaknesses vs Best Literature

Relative to the strongest references in `./literature` (especially Blinder-Watson and Santa-Clara/Valkanov):

Current strengths:

- Reproducibility discipline is stronger than most published writeups.
  - Full CLI pipeline, explicit specs, and machine-readable outputs (`scoreboard`, randomization tables, claims table).
- Multiplicity-aware reporting is stronger than most legacy papers.
  - We report `q_bh_fdr`, not only raw p-values, and keep CI bands visible.
- Sensitivity transparency is stronger.
  - We already compare baseline vs stricter profiles and record tier downgrades/upgrades.
- Congress-control diagnostics are broader.
  - We include both cross-regime and within-president unified/divided checks, instead of president-only comparisons.

Current weaknesses / gaps:

- Few-cluster econometric inference remains partially addressed.
  - We now publish HAC/Newey-West plus president-cluster sandwich diagnostics in `rb inference-table`, but cluster p-values still use a normal approximation (not wild-cluster bootstrap / exact few-cluster methods).
- Explanatory decomposition is less developed.
  - Blinder-Watson-style decomposition of the growth gap into candidate channels (oil, productivity, global growth, etc.) is not yet implemented.
- Small-cell/power diagnostics are not explicit enough.
  - We now report a rough MDE proxy for primary term-level metrics in `rb inference-table`, but we do not yet have equivalent power diagnostics for within-president estimands.
- Endpoint/vintage uncertainty is still under-documented.
  - We note data revision risk, but we do not yet version full vintages or publish a revision sensitivity panel.
- Congress-control interpretation remains diagnostic.
  - Within-president results are mostly exploratory at current sample sizes; this is useful but not decisive.

## Potential Next Steps (Methodology)

1. Strengthen few-cluster inference:
   - keep current permutation/q + HAC/Newey-West + president-cluster diagnostics, and add a small-cluster-robust p-value variant (for example wild-cluster bootstrap).
2. Pre-register a primary metric set and transform hierarchy in the spec:
   - one primary metric per family, with secondaries explicitly labeled.
3. Add power/precision diagnostics:
   - extend the current primary-term MDE diagnostics to within-president estimands and add bootstrap-SE style uncertainty diagnostics in the same table.
4. Implement a decomposition module for growth and labor gaps:
   - start with oil shock proxies, global growth, productivity, and initial-condition controls.
5. Add a historical-vintage sensitivity panel:
   - recompute headline claims using at least two download dates (or vintages where available).
6. Extend Congress checks with strict binary dominance framing:
   - president+both-houses vs all other regimes, with explicit cell-size and uncertainty caveats.
7. Apply publication-mode gating consistently across all publication-facing artifacts:
   - ensure all narrative/scoreboard export paths use publication-tier columns rather than raw randomization tiers.

## Immediate Next Steps

1. Add power diagnostics to the dual-inference outputs:
   - extend beyond primary term-level metrics and add equivalent diagnostics for within-president rows.
2. Strengthen few-cluster inference in `rb inference-table`:
   - add a small-cluster-robust p-value variant to complement current cluster-normal p-values.
3. Add manifest coverage for optional upstream dependency versions (for example package lock, CLI version string) to strengthen end-to-end reproducibility audits.

## Claims Table

A machine-readable baseline-vs-strict claims table is now produced via:

```sh
rb claims-table \
  --baseline-party-term reports/permutation_party_term_all_v1.csv \
  --strict-party-term reports/permutation_party_term_block20_all_v1.csv \
  --baseline-within reports/permutation_unified_within_term_all_v1.csv \
  --strict-within reports/permutation_unified_within_term_min90_all_v1.csv \
  --output reports/claims_table_v1.csv
```

Default invocation uses the same paths:

```sh
rb claims-table
```

Publication-gated variant:

```sh
rb claims-table --publication-mode \
  --inference-table reports/inference_table_primary_v1.csv
```

## Reproduce Current Outputs

```sh
uv sync
rb ingest --refresh
rb presidents --source congress_legislators --granularity tenure --refresh
rb compute
rb congress --refresh
rb regimes --refresh
rb randomization --all-metrics
rb scoreboard --all-metrics
rb validate
```

## Baseline vs Stricter Profile Commands

Baseline (current defaults used in most summaries):

```sh
rb randomization --all-metrics \
  --output-party-term reports/permutation_party_term_all_v1.csv \
  --output-unified-within-term reports/permutation_unified_within_term_all_v1.csv \
  --output-evidence-summary reports/permutation_evidence_summary_v1.csv \
  --output-evidence-md reports/permutation_evidence_summary_v1.md
```

Stricter sensitivity profile:

```sh
rb randomization --all-metrics \
  --term-block-years 20 \
  --within-president-min-window-days 90 \
  --output-party-term reports/permutation_party_term_block20_all_v1.csv \
  --output-unified-within-term reports/permutation_unified_within_term_min90_all_v1.csv \
  --output-evidence-summary reports/permutation_evidence_summary_block20_min90_v1.csv \
  --output-evidence-md reports/permutation_evidence_summary_block20_min90_v1.md
```

Compare profiles:

```sh
rb randomization-compare \
  --base-party-term reports/permutation_party_term_all_v1.csv \
  --alt-party-term reports/permutation_party_term_block20_all_v1.csv \
  --base-within reports/permutation_unified_within_term_all_v1.csv \
  --alt-within reports/permutation_unified_within_term_min90_all_v1.csv \
  --output reports/permutation_evidence_compare_v1.csv
```

Build claims table:

```sh
rb claims-table \
  --baseline-party-term reports/permutation_party_term_all_v1.csv \
  --strict-party-term reports/permutation_party_term_block20_all_v1.csv \
  --baseline-within reports/permutation_unified_within_term_all_v1.csv \
  --strict-within reports/permutation_unified_within_term_min90_all_v1.csv \
  --output reports/claims_table_v1.csv
```
